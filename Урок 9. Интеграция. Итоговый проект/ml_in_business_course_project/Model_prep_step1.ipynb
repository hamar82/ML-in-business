{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06554477",
   "metadata": {},
   "source": [
    "Отели играют решающую роль в путешествиях, и с расширением доступа к информации появились новые способы выбора лучших.\n",
    "С помощью этого набора данных, состоящего из 20 тысяч отзывов, полученных с сайта Tripadvisor, вы можете изучить, что делает отель отличным, и, возможно, даже использовать эту модель в своих путешествиях!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315fb0b7",
   "metadata": {},
   "source": [
    "[Датасет](https://www.kaggle.com/andrewmvd/trip-advisor-hotel-reviews)  \n",
    "&copy; Алам, М.Х., Рю, В.-Дж., Ли, С., 2016. Совместное многоплановое отношение к теме: моделирование семантических аспектов для онлайн-обзоров. Информационные науки 339, 206–223."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e86261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dill\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "from sklearn.metrics import roc_auc_score,roc_curve\n",
    "from sklearn.metrics import f1_score\n",
    "#working with text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#normalizing data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#pipeline\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import precision_score,recall_score\n",
    "#imputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import sklearn.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a999f166",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('tripadvisor_hotel_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662bf1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a2fe49",
   "metadata": {},
   "source": [
    "Целью модели будет предсказание эмоциональной окраски отзыва:  \n",
    "  0 - отрицательный(рейтинг 1-3),  \n",
    "  1  - положительный(рейтинг 4-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef7bc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(x):\n",
    "    if x<=3:\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "df['Sentiment']=df['Rating'].apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f138b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022f42c4",
   "metadata": {},
   "source": [
    "Поле Rating можем удалить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a4918e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop('Rating', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc49fbd6",
   "metadata": {},
   "source": [
    "Разделим датасет на тренировочную, валидационную и тестовую выборки. И сохраним тестовую выборку на диск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac66b054",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(df.iloc[:,:-1], df.iloc[:,-1], test_size= 0.2, random_state=24, stratify=df['Sentiment'])\n",
    "X_test.to_csv(\"X_test.csv\", index=None)\n",
    "y_test.to_csv(\"y_test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089fe3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val=train_test_split(X_train, y_train, test_size= 0.25, random_state=24, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36531f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fca458a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.key]\n",
    "    \n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on numeric columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[[self.key]]\n",
    "\n",
    "class FeatImp(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self.new_key='lenght'\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X[self.new_key]=X[self.key].apply(lambda x: len(x.strip().split()))\n",
    "        return X\n",
    "    \n",
    "class TextLemmatizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self.stop_words=stopwords.words('english')\n",
    "        self.lemmatizer=WordNetLemmatizer()\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X[self.key] = X[self.key].str.replace(r\"http\\S+\", \"\")\n",
    "        X[self.key] = X[self.key].str.replace(r\"http\",\"\")\n",
    "        X[self.key] = X[self.key].str.replace(r\"@/S+\",\"\")\n",
    "        X[self.key] = X[self.key].str.replace(r\"[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]\", \" \")\n",
    "        X[self.key] = X[self.key].str.replace(r\"@\",\" at \")\n",
    "        X[self.key] = X[self.key].str.lower()\n",
    "        X[self.key] = X[self.key].apply(self._lemm)\n",
    "        return X\n",
    "    \n",
    "    def _lemm(self, seq):\n",
    "        # review = regex.sub('[^a-zA-Z]', ' ', seq)    \n",
    "        review = review.split()    \n",
    "        review = [word for word in review if not word in set(self.stop_words)]    \n",
    "        review = [self.lemmatizer.lemmatize(word) for word in review]    \n",
    "        review = ' '.join(review)\n",
    "        return review\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e5d5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eacca1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_feat=Pipeline([\n",
    "    ('lemm', TextLemmatizer(key='Review')),\n",
    "    ('selector', ColumnSelector(key='Review')),\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1, 3),  max_features=10000, tokenizer = word_tokenize))\n",
    "    \n",
    "])\n",
    "next_feat=Pipeline([    \n",
    "    ('selector', NumberSelector(key='lenght'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15071735",
   "metadata": {},
   "outputs": [],
   "source": [
    "features=FeatureUnion([\n",
    "    ('rewiew', text_feat),\n",
    "    ('lenght', next_feat)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfa11d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model = Pipeline([('imp', FeatImp(key='Review')),\n",
    "    ('feat', features),\n",
    "    ('classifier', LogisticRegression()),\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403c90d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions=model.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc64e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_val,np.argmax(predictions,axis=1)))\n",
    "print(confusion_matrix(y_val, np.argmax(predictions,axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007124dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_score=predictions[:, 1][:], y_true=y_val.iloc[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f225f1e",
   "metadata": {},
   "source": [
    "Результаты вполне приемлимы, сохраним модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9475a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model.dill\", \"wb\") as f:\n",
    "    dill.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5538c89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
